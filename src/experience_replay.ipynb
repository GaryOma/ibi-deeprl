{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "from gym import wrappers, logger\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# def blotzmann(qvalues, tau=0.01):\n",
    "#     prob = []\n",
    "#     for qvalue in qvalues:\n",
    "#         prob.append()\n",
    "#     print(\"lol\")\n",
    "\n",
    "def epsilongreedy(qvalues, epsilon=0.5):\n",
    "    _, max_ind = qvalues.max(0)\n",
    "    return max_ind.item() if np.random.random() < epsilon else np.random.randint(len(qvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, observation_size, action_space):\n",
    "        self.mem = deque(maxlen=10000)\n",
    "        self.action_space = action_space\n",
    "        self.observation_size = observation_size\n",
    "        print(action_space)\n",
    "        layer_sizes = [\n",
    "            self.observation_size,\n",
    "            self.action_space.n\n",
    "        ]\n",
    "\n",
    "        self.W = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.W.append(torch.ones(layer_sizes[i + 1], layer_sizes[i]).type(torch.FloatTensor))\n",
    "\n",
    "    def choose_action(self, _observation, _reward, _done):\n",
    "        qvalues = self.qvalue(_observation)\n",
    "        action_ind = epsilongreedy(qvalues, epsilon=0.1)\n",
    "        print(self.action_space.sample(), action_ind)\n",
    "        return action_ind\n",
    "        # return self.action_space.sample()\n",
    "\n",
    "    def experience(self, _state, _action, _reward, _next_state, _done):\n",
    "        self.mem.append((_state, _action, _reward, _next_state, _done))\n",
    "\n",
    "    def minibatch(self, size=5):\n",
    "        batch_s = min(size, len(self.mem))\n",
    "        return random.sample(self.mem, batch_s)\n",
    "\n",
    "    def qvalue(self, state):\n",
    "        inp = torch.tensor(state).type(torch.FloatTensor)\n",
    "        for w in self.W[:-1]:\n",
    "            # inp = torch.cat((torch.Tensor([1.0]), inp))\n",
    "            # inp = func(torch.mv(w, inp))\n",
    "            inp = 1/(1 + torch.exp(-torch.mv(w, inp)))\n",
    "        return torch.mv(self.W[-1], inp.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Finished writing results. You can upload them to the scoreboard via gym.upload('/tmp/random-agent-results')\n",
      "INFO: Finished writing results. You can upload them to the scoreboard via gym.upload('/tmp/random-agent-results')\n",
      "INFO: Making new env: CartPole-v1\n",
      "INFO: Clearing 4 monitor files from previous run (because force=True was provided)\n",
      "Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "# You can set the level to logger.DEBUG or logger.WARN if you\n",
    "# want to change the amount of output.\n",
    "logger.set_level(logger.INFO)\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# You provide the directory to write to (can be an existing\n",
    "# directory, including one with existing data -- all monitor files\n",
    "# will be namespaced). You can also dump to a tempdir if you'd\n",
    "# like: tempfile.mkdtemp().\n",
    "outdir = '/tmp/random-agent-results'\n",
    "env = wrappers.Monitor(env, directory=outdir, force=True, video_callable=False)\n",
    "env.seed(0)\n",
    "observation_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "agent = Agent(observation_size, env.action_space)\n",
    "\n",
    "episode_count = 1000\n",
    "reward = 0\n",
    "done = False\n",
    "\n",
    "rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1 0\n",
      "1\n",
      "1 1\n",
      "1\n",
      "1 1\n",
      "1\n",
      "1 0\n",
      "1\n",
      "1 1\n",
      "1\n",
      "0 1\n",
      "1\n",
      "0 1\n",
      "1\n",
      "0 0\n",
      "1\n",
      "0 0\n",
      "1\n",
      "0 1\n",
      "1\n",
      "0 0\n",
      "1\n",
      "0 1\n",
      "1\n",
      "0 1\n",
      "1\n",
      "0 1\n",
      "1\n",
      "1 1\n",
      "1\n",
      "0 1\n",
      "1\n",
      "0 1\n",
      "1\n",
      "0 0\n",
      "INFO: Finished writing results. You can upload them to the scoreboard via gym.upload('/tmp/random-agent-results')\n"
     ]
    }
   ],
   "source": [
    "for i in range(episode_count):\n",
    "    ob = env.reset()\n",
    "    rewardSum = 0\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        action = agent.choose_action(ob, reward, done)\n",
    "        current_state = ob\n",
    "        ob, reward, done, _ = env.step(action)\n",
    "        rewardSum += reward\n",
    "        steps += 1\n",
    "\n",
    "        # Experience replay\n",
    "        agent.experience(current_state, action, reward, ob, done)\n",
    "        minibatch = agent.minibatch(size=10)\n",
    "        if done:\n",
    "            rewards.append(rewardSum)\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/home/gary/.virtualenvs/deeprl/bin/python",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "deeprl",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "deeprl"
  },
  "name": "experience_replay.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
